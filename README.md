<pre>      In the preceding chapter, we have calculated the chances of an event, knowing the circumstances </br>under which it is to happen or fail. We are now to place ourselves in an inverted position: we know the event,</br>and ask what is the probability which results from the event in favour of of any set of circumstances under </br>which the same might have happened.
</pre>
De Morgan (1838), An Essay on Probabilities, Ch. 3 "On Inverse Probabilities"

### What _was_ not clear about this term in the past?
The inventors of the term seemed to not notice the subtle difference between the probability of a real event and the "probability of the probability of an event having some particular value". The tautologically equivalent word 'likelihood' doesn't clarify the situation, it makes it even more vague and obscure.

### What do we do about this confusion?
Eigther we continue using this word 'Bayesian' all the time until the end of days or... Let's introduce an operator with a simple and obvious name 'inversion'. If you apply this operator to a probability distribution __function__ of some data you get an inverse probability distribution __function__. In the same way as you calculate an inverse function from a __functional equation__ y = __f__(x) by applying the __functional__ inversion operator (.)<sup>-1</sup> and getting an _inverse function_ __f__<sup>-1</sup>(y) and equate it to x because it is 'obvious' (or 'defined' somewhere) that __f__<sup>-1</sup>(__f__(x)) = x.
